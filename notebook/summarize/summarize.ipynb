{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the video transcripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from transcriber.data.utils import get_resource, check_create_fol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fol = get_resource(\"data_fol\")\n",
    "course_fol = data_fol / \"course\"\n",
    "transcripts_fol = course_fol / \"transcripts\"\n",
    "summaries_fol = course_fol / \"summaries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_create_fol(summaries_fol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate the topics in the transcripts folder\n",
    "transcripts_fol_iterdir = list(transcripts_fol.iterdir())\n",
    "for topic_fol in transcripts_fol_iterdir[2:]:\n",
    "    if not topic_fol.is_dir():\n",
    "        continue\n",
    "    topic_name = topic_fol.name\n",
    "    print(topic_name)\n",
    "\n",
    "    # iterate the lessons in the topic folder\n",
    "    topic_fol_iterdir = list(topic_fol.iterdir())\n",
    "    for lesson_fp in topic_fol_iterdir[1:]:\n",
    "        if not lesson_fp.is_file():\n",
    "            continue\n",
    "        lesson_name = lesson_fp.stem\n",
    "        print(lesson_name)\n",
    "\n",
    "        # load the transcript\n",
    "        transcript_orig_text = lesson_fp.read_text()\n",
    "        # remove spaces at beginning and end\n",
    "        transcript_orig_text = transcript_orig_text.strip()\n",
    "        # remove newlines\n",
    "        transcript_orig_text = transcript_orig_text.replace(\"\\n\", \" \")\n",
    "        word_count = len(transcript_orig_text.split())\n",
    "        print(f\"word count: {word_count}\")\n",
    "        print(transcript_orig_text)\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fol = get_resource(\"quant_model_fol\")\n",
    "\n",
    "for mn in model_fol.iterdir():\n",
    "    print(mn.name)\n",
    "\n",
    "# model_name = \"mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n",
    "# model_name = \"mistral-7b-instruct-v0.2.Q8_0.gguf\"\n",
    "# model_name = \"codellama-34b-instruct.Q5_K_M.gguf\"\n",
    "model_name = \"mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf\"\n",
    "model_path = model_fol / model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = \"\"\"given the following transcript of a speech, please provide a one paragraph summary.\n",
    "# take care of summarizing only the provided information, without introducing external knowledge.\n",
    "# do not add an explanation, and do not include the question in the summary.\n",
    "# \"\"\"\n",
    "\n",
    "context = \"\"\"given the following transcript of a speech, please provide a summary.\n",
    "take care of summarizing only the provided information, without introducing external knowledge.\n",
    "do not add an explanation, and do not include the question in the summary.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpl_transcript = \"\"\"{context}\n",
    "Summarize the following transcript of a speech:\n",
    "{transcript_orig_text}\n",
    "\"\"\"\n",
    "\n",
    "prompt_transcript = PromptTemplate(\n",
    "    input_variables=[\n",
    "        \"context\",\n",
    "        \"transcript_orig_text\",\n",
    "    ],\n",
    "    template=tmpl_transcript,\n",
    ")\n",
    "\n",
    "fill_prompt_transcript = prompt_transcript.format(\n",
    "    context=context,\n",
    "    transcript_orig_text=transcript_orig_text,\n",
    ")\n",
    "print(fill_prompt_transcript[:60000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ctx = 2**13\n",
    "print(f\"using {n_ctx=}\")\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=str(model_path),\n",
    "    # n_ctx=32768,  # The max sequence length to use - note that longer sequence lengths require much more resources\n",
    "    n_ctx=n_ctx,  # The max sequence length to use - note that longer sequence lengths require much more resources\n",
    "    n_threads=16,  # The number of CPU threads to use, tailor to your system and the resulting performance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm(\n",
    "    fill_prompt_transcript,\n",
    "    max_tokens=512,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.keys())\n",
    "print(output[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output[\"choices\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assistant prompt\n",
    "\n",
    "now let's create a prompt for that assistant. follow the steps below to create a\n",
    "prompt that will help the assistant perform the task of summarizing a video\n",
    "transcript.\n",
    "\n",
    "Set the context: Start by specifying the role you want the assistant to play.\n",
    "This helps set the expectations and provides a frame of reference for the\n",
    "generated responses.\n",
    "\n",
    "State the requirements: Clearly state what you need from the assistant, such as\n",
    "a recommendation, solution, or answer. This helps narrow down the focus of the\n",
    "conversation.\n",
    "\n",
    "Define the task: Describe the specific task or action that the assistant should\n",
    "perform. This provides clarity on the desired outcome.\n",
    "\n",
    "Provide details: Specify any additional details or considerations that should be\n",
    "taken into account during the task.\n",
    "\n",
    "Mention restrictions: Clearly state any limitations or restrictions that should\n",
    "be followed. This helps avoid generating responses that are not suitable or\n",
    "desired.\n",
    "\n",
    "Specify the desired format: Indicate the format or structure in which you would\n",
    "like the final result to be presented. This ensures the generated output aligns\n",
    "with your expectations.\n",
    "\n",
    "Provide examples: Include examples to give the assistant a reference point and\n",
    "help it understand the type of response you are looking for. This can improve\n",
    "the quality and relevance of the generated answers.\n",
    "\n",
    "Remember, assigning the assistant a specific role and providing clear\n",
    "instructions through a well constructed prompt increases the likelihood of\n",
    "obtaining accurate and useful responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context:\n",
    "You are an editor with strong reading comprehension, concise communication skills and good attention to detail.\n",
    "\n",
    "Requirements:\n",
    "You must generate clear and coherent summaries for video transcripts.\n",
    "The goal is to distill the key information, main points, and important details while maintaining accuracy and relevance.\n",
    "\n",
    "Task:\n",
    "Please summarize the provided video transcript on the given topic.\n",
    "\n",
    "<!-- Your summary should have a schematic structure with sections and lists to capture the essence of the content. -->\n",
    "\n",
    "Your summary should have a schematic structure with sections for each subtopic in the video transcript.\n",
    "Where needed, you can use bullet points to capture the essence of the content.\n",
    "\n",
    "Details:\n",
    "Take into account the context of the video and focus on highlighting major themes, key takeaways, and any notable examples or explanations provided.\n",
    "\n",
    "Restrictions:\n",
    "Only summarize information that is present in the video transcript.\n",
    "Do not include any additional information or make any assumptions.\n",
    "Refrain from introducing personal opinions or biases in the summary.\n",
    "Stick to a neutral and informative tone.\n",
    "\n",
    "Desired Format:\n",
    "Format the summary as valid markdown text.\n",
    "\n",
    "Examples:\n",
    "For a video on renewable energy, a suitable summary might cover the importance of renewable sources, advancements in technology, and potential environmental benefits. Provide similar structured summaries for various topics based on the specific video content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Context:\n",
    "You are an editor with strong reading comprehension, concise communication skills and good attention to detail.\n",
    "\n",
    "Requirements:\n",
    "You must generate clear and coherent summaries for video transcripts.\n",
    "The goal is to distill the key information, main points, and important details while maintaining accuracy and relevance.\n",
    "\n",
    "Task:\n",
    "Please summarize the provided video transcript on the given topic.\n",
    "Your summary should have a schematic structure with sections and lists to capture the essence of the content.\n",
    "\n",
    "Details:\n",
    "Take into account the context of the video and focus on highlighting major themes, key takeaways, and any notable examples or explanations provided.\n",
    "\n",
    "Restrictions:\n",
    "Only summarize information that is present in the video transcript.\n",
    "Do not include any additional information or make any assumptions.\n",
    "Refrain from introducing personal opinions or biases in the summary.\n",
    "Stick to a neutral and informative tone.\n",
    "\n",
    "Desired Format:\n",
    "Format the summary as valid markdown text.\n",
    "\"\"\"\n",
    "\n",
    "context = \"\"\"Context: You are an editor with strong reading comprehension, concise communication skills and good attention to detail.\n",
    "\n",
    "Requirements: You must generate clear and coherent summaries for video transcripts. The goal is to distill the key information, main points, and important details while maintaining accuracy and relevance.\n",
    "\n",
    "Task: Please summarize the provided video transcript on the given topic. Your summary should have a schematic structure with sections for each subtopic in the video transcript. Where needed, you can use bullet points to capture the essence of the content.\n",
    "\n",
    "Details: Take into account the context of the video and focus on highlighting major themes, key takeaways, and any notable examples or explanations provided.\n",
    "\n",
    "Restrictions: Only summarize information that is present in the video transcript. Do not include any additional information or make any assumptions. Refrain from introducing personal opinions or biases in the summary. Stick to a neutral and informative tone.\n",
    "\n",
    "Desired Format: Format the summary as valid markdown text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Summarize the following transcript of a speech:\n",
    "{transcript_orig_text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": context},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_gpt3(\n",
    "    prompt,\n",
    "    context,\n",
    "    client: OpenAI,\n",
    "    # max_tokens=NOT_GIVEN,\n",
    "):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": context},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        # max_tokens=max_tokens,\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate the topics in the transcripts folder\n",
    "transcripts_fol_iterdir = list(transcripts_fol.iterdir())\n",
    "for topic_fol in transcripts_fol_iterdir[0:]:\n",
    "    if not topic_fol.is_dir():\n",
    "        continue\n",
    "    topic_name = topic_fol.name\n",
    "    print(topic_name)\n",
    "    # create the topic folder in the summary folder\n",
    "    topic_sum_fol = summaries_fol / topic_name\n",
    "    check_create_fol(topic_sum_fol)\n",
    "\n",
    "    # iterate the lessons in the topic folder\n",
    "    topic_fol_iterdir = list(topic_fol.iterdir())\n",
    "    for lesson_fp in topic_fol_iterdir[0:]:\n",
    "        if not lesson_fp.is_file():\n",
    "            continue\n",
    "        lesson_name = lesson_fp.stem\n",
    "        print(\"  \", lesson_name)\n",
    "\n",
    "        # build the output md file name\n",
    "        summary_fp = topic_sum_fol / f\"{lesson_name}.md\"\n",
    "        # if the summary file already exists, skip it\n",
    "        if summary_fp.exists():\n",
    "            continue\n",
    "\n",
    "        # load the transcript\n",
    "        transcript_orig_text = lesson_fp.read_text()\n",
    "        # remove spaces at beginning and end\n",
    "        transcript_orig_text = transcript_orig_text.strip()\n",
    "        # remove newlines\n",
    "        transcript_orig_text = transcript_orig_text.replace(\"\\n\", \" \")\n",
    "        # word_count = len(transcript_orig_text.split())\n",
    "        # print(f\"word count: {word_count}\")\n",
    "        # print(transcript_orig_text[:100])\n",
    "\n",
    "        # summarize the transcript\n",
    "        summary_text = get_summary_gpt3(\n",
    "            prompt=transcript_orig_text,\n",
    "            context=context,\n",
    "            client=client,\n",
    "        )\n",
    "        if summary_text is None:\n",
    "            print(\"    no summary\")\n",
    "            summary_text = \"\"\n",
    "        # write the summary to file\n",
    "        summary_fp.write_text(summary_text)\n",
    "\n",
    "    #     break\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcriber-cm8gQC0C-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
